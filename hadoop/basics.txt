Installing Google cloud CLI:
-----------------------------
1) open powershell in admin mode
2) run the below commands
(New-Object Net.WebClient).DownloadFile("https://dl.google.com/dl/cloudsdk/channels/rapid/GoogleCloudSDKInstaller.exe", "$env:Temp\GoogleCloudSDKInstaller.exe")

& $env:Temp\GoogleCloudSDKInstaller.exe


3) install putty from google. [important]  link : https://www.putty.org/
    
one done -> open the google cloud cli 
1) gcloud init
2) To continue, you must log in. Would you like to log in (Y/n)? Y
3) Pick cloud project to use:
 [1] [my-project-1]
 [2] [my-project-2]
 ...
 Please enter your numeric choice:

reference: https://cloud.google.com/sdk/docs/install-sdk


playing around with linux OS:
------------------------------

open your cluster / VM. 

gsutil cp -r gs://data1509/hive_data/ ./

1) creating directory structures (or folders)

mkdir data 
mkdir bin 
mkdir logs 


2) Navigate, Creating files , copying files , listing files. 

change the directory => cd date
creating an empty file=> touch test.txt 
write some contents into file => vi test.txt 
Save the contenets : esc + :wq!   

pwd [present working directory]
ls [lists the contents of the current directory]
ls -l [long listing : Shows files along with file properties]
ls -ltr [lists the contents in the reverse order of timestamp (most recent file at the bottom)]


3) removing files and directires.
rm 
rm -r 


4) understanding permission for group , users 

d      - Type of the file. d shows it is a directory
rwx    - Permissions for the owner = 7
rwx    - Permissions for the group = 6
r-x    - Permissions for all other users   = 4


r  - Read permission
w  - Write permission
x  - Execute permission


-rw-r--r-- 12 linuxize users 12.0K Apr  28 10:10 file_name
|[-][-][-]-   [------] [---]
| |  |  | |      |       |
| |  |  | |      |       +-----------> 7. Group
| |  |  | |      +-------------------> 6. Owner
| |  |  | +--------------------------> 5. Alternate Access Method
| |  |  +----------------------------> 4. Others Permissions
| |  +-------------------------------> 3. Group Permissions
| +----------------------------------> 2. Owner Permissions
+------------------------------------> 1. File Type


5) how to change permission


     read       -  4
     write      -  2
     execute    -  1

     chmod 760 vi_sample.txt  : Octal notation to change the file permissions of files
     chmod 764 testfile.txt
     chmod 777 pgm.sh
	 
	 

6) how create a sample job in shell and run the job. 

open vi pgm.sh 
enter -> i 
for copy paste -> shift + insert key. 

#!/bin/bash
n=10
if [ $n -lt 10 ];
then
echo "It is a one digit number"
else
echo "It is a two digit number"
fi



7) removing first line of a file 

sed '1d' Top_tech_companies.csv > Top_tech_companies_no_header.csv 


gsutil:
=======
copy from google cloud stroage into your cluster 

gsutil cp -r gs://datasetupguvi/* ./


Hadoop commands:
-----------------

hadoop fs /[hdfs dfs]


1. Create a file in linux copying the file to hadoop 
/home/Raj/data/hive_data/Top_tech_companies_no_header.csv

2. Create a directory in hdfs 
hadoop fs -mkdir /mydata/

3) copy the files from local to hdfs storage.

hadoop fs -put /home/Raj/data/hive_data/Top_tech_companies_no_header.csv /mydata/Top_tech_companies_no_header.csv


4) Display from hdfs 

hadoop fs -ls /mydata/


5) Download the data from hdfs to local 

hadoop fs -get /mydata/txns /home/Raj/logs


6) hadoop remove  

hadoop fs -rm /mydata/txns

7) set the blocksize 128MB while writing the file in HDFS

hadoop fs -D dfs.block.size=134217728 -put /home/Raj/data/hive_data/txns_20181212_NY /mydata/

8) display contents from hadoop 

hadoop fs -cat <file path>

9) To check the block information

hdfs fsck /mydata/txns_20181212_NY -files -locations -blocks