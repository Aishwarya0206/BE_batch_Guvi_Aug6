spark Core:
-----------
Architecure
patitioning
pypsark program   [job (task, stages) = tranfromation + actions ]
    job1= tranformations + actions 
    job2= tranformations                            + tranformations            +   tranformations +    action 
          4 partitions                             same 4 partitions                same 4 partitions    
          (4 taks will be launched in executer)   (4 taks will be launched in executer)
          Stage 1                   --->            stage 2             ---> stage3 ->         + action 
    job3= tranformations + actions 
        = tranformations + tranformations    / this is not even a job. 
    job5= tranformations + actions 

    job5= job(tranformations + actions )+ action + action .... 

    job.....n= tranformations + actions 

memory mangement
spark UI. 


Spark DF:
-----------
1) DF basics 
2) DF reader / Writer 
    - spark.read
    - spark.write
3) type of data handelling:
    - Structured 
    - semi structured 
    - unstructured


Spark Streaming:
---------------